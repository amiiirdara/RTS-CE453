{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Real-Time Systems Project**\n",
        "\n",
        "### Amir Mahdi Daraei 99105431\n",
        "\n",
        "### Amirreza Abootalebi 99105197"
      ],
      "metadata": {
        "id": "8dzZaFi8TTpg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Documentation -- PHASE 1\n",
        "\n",
        "#### Group No. 22 -- Project No. 9\n",
        "\n",
        "#### Course: Real-Time Systems\n",
        "#### Teaching Assistant: Mrs. Maleki\n",
        "#### Title: Scheduling and Mapping Critical Mixed Tasks in Multi-Criticality Systems\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "HkyAGof-Wxec"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Introduction\n",
        "In a modern car, various units like the engine control unit (high criticality level) and the infotainment system (low criticality level) coexist. These systems must operate simultaneously and in harmony, ensuring the execution of their critical tasks. In this project, a two-level mixed-criticality system with periodic LC and HC tasks is designed. LC tasks have one worst-case execution time, while HC tasks have two worst-case execution times. The system starts in the normal mode and transitions to the overrun mode if any HC task exceeds its small execution time without completion."
      ],
      "metadata": {
        "id": "IE89ZMUcXYwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Project Goals\n",
        "- Implement task mapping algorithms based on resource overload and core utilization.\n",
        "- Evaluate and compare the proposed mapping algorithms with WFD.\n",
        "- Present results as schedulability and mapping capability charts.\n"
      ],
      "metadata": {
        "id": "312mG7GjXb4G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 0: Imports**"
      ],
      "metadata": {
        "id": "ipx9qiB8bwqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import heapq\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UfoyisNjbyPS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 1: Algorithm Implementation**\n"
      ],
      "metadata": {
        "id": "lflSz8jEXJix"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Task Class\n",
        "The Task class represents a task with attributes like LC and HC execution times, deadline, period, criticality, and required resources.\n"
      ],
      "metadata": {
        "id": "geqtNM2EXTqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Task:\n",
        "    \"\"\"\n",
        "    A class representing a task with attributes for LC and HC execution times, deadline, period, criticality, and resources.\n",
        "\n",
        "    Attributes:\n",
        "        id (int): Identifier for the task.\n",
        "        exec_time_lc (float): Execution time for low criticality mode.\n",
        "        exec_time_hc (list of float): Execution times for high criticality mode (two values).\n",
        "        deadline (int): Deadline for the task.\n",
        "        period (int): Period of the task.\n",
        "        criticality (str): Criticality level ('LC' or 'HC').\n",
        "        remaining_time (float): Remaining execution time for the task.\n",
        "        state (str): State of the task ('Normal' or 'Overrun').\n",
        "        resources (list of int): List of resources the task needs access to.\n",
        "    \"\"\"\n",
        "    def __init__(self, id, exec_time_lc, exec_time_hc, deadline, period, criticality, resources):\n",
        "        self.id = id\n",
        "        self.exec_time_lc = exec_time_lc\n",
        "        self.exec_time_hc = exec_time_hc\n",
        "        self.deadline = deadline\n",
        "        self.period = period\n",
        "        self.criticality = criticality\n",
        "        self.remaining_time = exec_time_lc if criticality == 'LC' else exec_time_hc[0]\n",
        "        self.state = 'Normal'\n",
        "        self.resources = resources\n",
        "\n",
        "    def __lt__(self, other):\n",
        "        return self.deadline < other.deadline"
      ],
      "metadata": {
        "id": "G0soEQrBTSGT"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Core Class\n",
        "The Core class represents a processing core that maintains tasks and current core utilization."
      ],
      "metadata": {
        "id": "4DEfW3cdXprW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Core:\n",
        "    \"\"\"\n",
        "    A class representing a processing core with attributes for utilization and tasks.\n",
        "\n",
        "    Attributes:\n",
        "        id (int): Identifier for the core.\n",
        "        utilization (float): Current utilization of the core.\n",
        "        tasks (list of Task): List of tasks assigned to the core.\n",
        "    \"\"\"\n",
        "    def __init__(self, id):\n",
        "        self.id = id\n",
        "        self.utilization = 0\n",
        "        self.tasks = []\n",
        "\n",
        "    def add_task(self, task):\n",
        "        \"\"\"\n",
        "        Adds a task to the core and updates the core's utilization.\n",
        "\n",
        "        Args:\n",
        "            task (Task): The task to add to the core.\n",
        "        \"\"\"\n",
        "        self.tasks.append(task)\n",
        "        self.utilization += task.exec_time_lc / task.period\n"
      ],
      "metadata": {
        "id": "44QVpws1XqUx"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Uunifast Function and Generating Synthetic Tasks\n",
        "The first function generates a set of utilizations for tasks using the UUnifast algorithm and the second one generates synthetic tasks with specified utilization and different criticality levels."
      ],
      "metadata": {
        "id": "lmnqMlGEYCTy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def uunifast(num_tasks, total_util):\n",
        "    \"\"\"\n",
        "    Generates a list of utilizations for tasks using the UUnifast algorithm.\n",
        "\n",
        "    Args:\n",
        "        num_tasks (int): Number of tasks.\n",
        "        total_util (float): Total utilization to be distributed among the tasks.\n",
        "\n",
        "    Returns:\n",
        "        list of float: List of utilizations for the tasks.\n",
        "    \"\"\"\n",
        "    utilizations = []\n",
        "    sum_util = total_util\n",
        "    for i in range(1, num_tasks):\n",
        "        next_util = sum_util * (1 - random.random() ** (1 / (num_tasks - i)))\n",
        "        utilizations.append(next_util)\n",
        "        sum_util -= next_util\n",
        "    utilizations.append(sum_util)\n",
        "    return utilizations\n",
        "\n",
        "def generate_tasks(num_tasks, total_util, criticality_levels):\n",
        "    \"\"\"\n",
        "    Generates a list of tasks with given utilization and criticality levels.\n",
        "\n",
        "    Args:\n",
        "        num_tasks (int): Number of tasks.\n",
        "        total_util (float): Total utilization for the tasks.\n",
        "        criticality_levels (list of str): List of criticality levels to be assigned to tasks.\n",
        "\n",
        "    Returns:\n",
        "        list of Task: Generated list of tasks.\n",
        "    \"\"\"\n",
        "    utilizations = uunifast(num_tasks, total_util)\n",
        "    tasks = []\n",
        "    for i, u in enumerate(utilizations):\n",
        "        period = random.randint(10, 100)\n",
        "        exec_time_lc = u * period\n",
        "        exec_time_hc = [exec_time_lc, exec_time_lc * random.uniform(1.1, 2)] if 'HC' in criticality_levels else [exec_time_lc, exec_time_lc]\n",
        "        criticality = random.choice(criticality_levels)\n",
        "        resources = random.sample(range(1, 7), random.randint(2, 6))\n",
        "        tasks.append(Task(i+1, exec_time_lc, exec_time_hc, period, period, criticality, resources))\n",
        "    return tasks"
      ],
      "metadata": {
        "id": "xPwmF60rYJLI"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Calculating Resource Overload\n",
        "This function calculates the resource overload for a task on a core."
      ],
      "metadata": {
        "id": "rXL4t8JjYl4F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_resource_overload(task, core):\n",
        "    \"\"\"\n",
        "    Calculates the resource overload for a given task on a core.\n",
        "\n",
        "    Args:\n",
        "        task (Task): The task for which to calculate resource overload.\n",
        "        core (Core): The core on which the resource overload is calculated.\n",
        "\n",
        "    Returns:\n",
        "        float: The calculated resource overload.\n",
        "    \"\"\"\n",
        "    overload = 0\n",
        "    for resource in task.resources:\n",
        "        resource_usage = sum([t.exec_time_lc if t.criticality == 'LC' else t.exec_time_hc[0] for t in core.tasks if resource in t.resources])\n",
        "        overload += resource_usage\n",
        "    return overload"
      ],
      "metadata": {
        "id": "-37re_CMYrGi"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Assigning Tasks to Cores\n",
        "This function assigns tasks to cores based on resource overload and utilization.\n"
      ],
      "metadata": {
        "id": "r5fOygEUYyvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def heuristic_mapping(tasks, cores):\n",
        "    \"\"\"\n",
        "    Assigns tasks to cores based on resource overload and utilization.\n",
        "\n",
        "    Args:\n",
        "        tasks (list of Task): List of tasks to be assigned.\n",
        "        cores (list of Core): List of cores to which tasks are assigned.\n",
        "\n",
        "    Returns:\n",
        "        float: The ratio of successfully assigned tasks to the total number of tasks.\n",
        "    \"\"\"\n",
        "    assigned_tasks = 0\n",
        "    for task in tasks:\n",
        "        cores.sort(key=lambda core: (-calculate_resource_overload(task, core), core.utilization))\n",
        "        for core in cores:\n",
        "            remaining_utilization = 1 - core.utilization\n",
        "            task_utilization = task.exec_time_lc / task.period\n",
        "            if remaining_utilization >= task_utilization:\n",
        "                core.add_task(task)\n",
        "                assigned_tasks += 1\n",
        "                break\n",
        "    return assigned_tasks / len(tasks)"
      ],
      "metadata": {
        "id": "CBgUanfPZp4X"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####WFD Mapping\n",
        "Assigns tasks to cores using the Worst-Fit Decreasing (WFD) algorithm."
      ],
      "metadata": {
        "id": "8sezwQ-7sbxa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def wfd_mapping(tasks, cores):\n",
        "    \"\"\"\n",
        "    Assigns tasks to cores using the Worst-Fit Decreasing (WFD) algorithm.\n",
        "\n",
        "    Args:\n",
        "        tasks (list of Task): List of tasks to be assigned.\n",
        "        cores (list of Core): List of cores to which tasks are assigned.\n",
        "\n",
        "    Returns:\n",
        "        float: The ratio of successfully assigned tasks to the total number of tasks.\n",
        "    \"\"\"\n",
        "    assigned_tasks = 0\n",
        "    for task in tasks:\n",
        "        cores.sort(key=lambda core: core.utilization)  # Sort cores by current utilization in ascending order\n",
        "        for core in cores:\n",
        "            remaining_utilization = 1 - core.utilization\n",
        "            task_utilization = task.exec_time_lc / task.period\n",
        "            if remaining_utilization >= task_utilization:\n",
        "                core.add_task(task)\n",
        "                assigned_tasks += 1\n",
        "                break\n",
        "    return assigned_tasks / len(tasks)"
      ],
      "metadata": {
        "id": "GmJxyLNewg5t"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 2: Evaluating and Comparing Mapping Capability**"
      ],
      "metadata": {
        "id": "ymg8HQ2MaPTE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Mapping Capability Evaluation Function\n",
        "This function evaluates the mapping capability of the heuristic and WFD algorithms.\n"
      ],
      "metadata": {
        "id": "rCk6s5b0aZvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_mapping_capability(num_tasks, total_utils, criticality_levels, num_cores, num_runs):\n",
        "    \"\"\"\n",
        "    Evaluates the mapping capability of the heuristic and WFD algorithms.\n",
        "\n",
        "    Args:\n",
        "        num_tasks (int): Number of tasks.\n",
        "        total_utils (list of float): List of total utilizations to be tested.\n",
        "        criticality_levels (list of str): List of criticality levels.\n",
        "        num_cores (int): Number of cores.\n",
        "        num_runs (int): Number of runs for each configuration.\n",
        "\n",
        "    Returns:\n",
        "        dict: Results of mapping capabilities for each utilization level.\n",
        "    \"\"\"\n",
        "    results = {util: [] for util in total_utils}\n",
        "\n",
        "    for util in total_utils:\n",
        "        for _ in range(num_runs):\n",
        "            tasks = generate_tasks(num_tasks, util, criticality_levels)\n",
        "\n",
        "            # Heuristic mapping algorithm\n",
        "            heuristic_cores = [Core(i+1) for i in range(num_cores)]\n",
        "            heuristic_mapping_rate = heuristic_mapping(tasks, heuristic_cores)\n",
        "\n",
        "            # WFD algorithm\n",
        "            wfd_cores = [Core(i+1) for i in range(num_cores)]\n",
        "            wfd_mapping_rate = wfd_mapping(tasks, wfd_cores)\n",
        "\n",
        "            results[util].append((heuristic_mapping_rate, wfd_mapping_rate))\n",
        "    return results"
      ],
      "metadata": {
        "id": "4zqD-0ubaXF0"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 3: Running Evaluations and Plotting Results**"
      ],
      "metadata": {
        "id": "Bw1Oq3wHa4K6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Evaluation Settings\n",
        "The evaluation settings include the number of tasks, utilizations, criticality levels, number of cores, and the number of runs."
      ],
      "metadata": {
        "id": "XXWwJLWJa9qS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_tasks = 400\n",
        "total_utils = [0.25, 0.5]\n",
        "criticality_levels = ['LC', 'HC']\n",
        "num_cores_list = [2, 4, 8]\n",
        "num_runs = 10\n",
        "hyper_period = 200"
      ],
      "metadata": {
        "id": "iPVAqYKca8Sg"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluations for mapping capability is performed for each number of cores and different utilizations."
      ],
      "metadata": {
        "id": "KdQaJOsubJe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate mapping capability\n",
        "mapping_results = {}\n",
        "\n",
        "for num_cores in num_cores_list:\n",
        "    mapping_results[num_cores] = evaluate_mapping_capability(num_tasks, total_utils, criticality_levels, num_cores, num_runs)\n",
        "\n",
        "# Plot mapping capability results\n",
        "for num_cores, results in mapping_results.items():\n",
        "    plt.figure()\n",
        "    for util, data in results.items():\n",
        "        heuristic_mapping_rates = [d[0] for d in data]\n",
        "        wfd_mapping_rates = [d[1] for d in data]\n",
        "        plt.plot(heuristic_mapping_rates, label=f'Heuristic (Util={util})')\n",
        "        plt.plot(wfd_mapping_rates, label=f'WFD (Util={util})')\n",
        "    plt.xlabel('Run')\n",
        "    plt.ylabel('Mapping Capability')\n",
        "    plt.title(f'Mapping Capability Comparison with {num_cores} Cores')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "EeY_4eMUbHJN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Part 4: Conclusion**"
      ],
      "metadata": {
        "id": "-Ek-hGj1bSGa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**In this project, task mapping algorithms in a two-level mixed-criticality system were implemented and evaluated. The evaluation results were presented as mapping capability charts, showing the performance of the proposed algorithm compared to the WFD algorithm.**"
      ],
      "metadata": {
        "id": "MZj8fFjVbija"
      }
    }
  ]
}